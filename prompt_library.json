[
  {
    "prompt": "Show me the top 5 sellers with the highest internal risk rating and most escalations.",
    "intent_description": "Ranking with CASE + Sorting",
    "expected_code": "df.sort_values(by=['internal_risk_rating', 'escalation_count'], ascending=[False, False]).head(5)",
    "expected_output": "Top 5 sellers sorted by risk rating and escalation count",
    "output_type": "Value",
    "category": "Ranking with CASE + Sorting",
    "python_code": "df.sort_values(by=['internal_risk_rating', 'escalation_count'], ascending=[False, False]).head(5)"
  },
  {
    "prompt": "What\u2019s the average identity, UBO, and geo risk score by service category?",
    "intent_description": "Aggregated Averages by Group",
    "expected_code": "df.groupby('service_category')[['identity_verification_score', 'ubo_transparency_score', 'geo_risk_score']].mean().sort_values('geo_risk_score', ascending=False)",
    "expected_output": "Average identity, UBO, and geo scores per service category",
    "output_type": "DataFrame",
    "category": "Aggregated Averages by Group",
    "python_code": "df.groupby('service_category')[['identity_verification_score', 'ubo_transparency_score', 'geo_risk_score']].mean().sort_values('geo_risk_score', ascending=False)"
  },
  {
    "prompt": "List sellers who had very high onboarding time anomalies.",
    "intent_description": "Anomaly Detection",
    "expected_code": "df[df['onboarding_time_anomaly'] > 0.8].sort_values('onboarding_time_anomaly', ascending=False)",
    "expected_output": "Sellers with high anomaly scores in onboarding",
    "output_type": "DataFrame",
    "category": "Anomaly Detection",
    "python_code": "df[df['onboarding_time_anomaly'] > 0.8].sort_values('onboarding_time_anomaly', ascending=False)"
  },
  {
    "prompt": "Group sellers by account age (New, Mid, Established) and show percent with high risk.",
    "intent_description": "Bucketizing with CASE",
    "expected_code": "df.assign(age_group=pd.cut(df['registration_age_months'], bins=[0,12,36,999], labels=['New','Mid','Established'])).groupby('age_group').agg({'seller_id':'count', 'internal_risk_rating': lambda x: (x=='High').mean()*100})",
    "expected_output": "Seller count and high-risk % by account age group",
    "output_type": "DataFrame",
    "category": "Bucketizing with CASE",
    "python_code": "df.assign(age_group=pd.cut(df['registration_age_months'], bins=[0,12,36,999], labels=['New','Mid','Established'])).groupby('age_group').agg({'seller_id':'count', 'internal_risk_rating': lambda x: (x=='High').mean()*100})"
  },
  {
    "prompt": "How many sellers haven't completed bank verification?",
    "intent_description": "Missing Value Filter",
    "expected_code": "df[df['bank_account_verification'] == 0].shape[0]",
    "expected_output": "Total number of sellers missing bank verification",
    "output_type": "DataFrame",
    "category": "Missing Value Filter",
    "python_code": "df[df['bank_account_verification'] == 0].shape[0]"
  },
  {
    "prompt": "What\u2019s the correlation between document completeness and remediation effectiveness?",
    "intent_description": "Correlation Analysis",
    "expected_code": "df['doc_completeness_score'].corr(df['remediation_effectiveness_score'])",
    "expected_output": "Correlation value between document completeness and remediation scores",
    "output_type": "DataFrame",
    "category": "Correlation Analysis",
    "python_code": "df['doc_completeness_score'].corr(df['remediation_effectiveness_score'])"
  },
  {
    "prompt": "Which sellers had different internal risk ratings over time?",
    "intent_description": "Behavioral Volatility",
    "expected_code": "df.groupby('seller_id')['internal_risk_rating'].nunique().reset_index().query('internal_risk_rating > 1')",
    "expected_output": "Sellers with multiple distinct risk ratings",
    "output_type": "DataFrame",
    "category": "Behavioral Volatility",
    "python_code": "df.groupby('seller_id')['internal_risk_rating'].nunique().reset_index().query('internal_risk_rating > 1')"
  },
  {
    "prompt": "Find high-risk sellers with control coverage scores below 70.",
    "intent_description": "Multi-Criteria Filter",
    "expected_code": "df[(df['internal_risk_rating']=='High') & (df['control_coverage_score'] < 70)].sort_values('control_coverage_score')",
    "expected_output": "List of high-risk sellers with low control coverage score",
    "output_type": "DataFrame",
    "category": "Multi-Criteria Filter",
    "python_code": "df[(df['internal_risk_rating']=='High') & (df['control_coverage_score'] < 70)].sort_values('control_coverage_score')"
  },
  {
    "prompt": "Give me a count of sellers by service category and their risk level.",
    "intent_description": "Heatmap Layout",
    "expected_code": "df.groupby(['service_category', 'internal_risk_rating'])['seller_id'].count().reset_index()",
    "expected_output": "Seller count per risk level and service category",
    "output_type": "DataFrame",
    "category": "Heatmap Layout",
    "python_code": "df.groupby(['service_category', 'internal_risk_rating'])['seller_id'].count().reset_index()"
  },
  {
    "prompt": "Which service categories have the most historical compliance issues?",
    "intent_description": "Policy Violation Totals",
    "expected_code": "df.groupby('service_category')['historical_compliance_findings'].sum().sort_values(ascending=False).head(5)",
    "expected_output": "Top 5 service categories with the most compliance issues",
    "output_type": "DataFrame",
    "category": "Policy Violation Totals",
    "python_code": "df.groupby('service_category')['historical_compliance_findings'].sum().sort_values(ascending=False).head(5)"
  },
  {
    "prompt": "Show the 10 sellers with the worst order defect rates.",
    "intent_description": "Top-N Risk by Metric",
    "expected_code": "df.sort_values(by='order_defect_rate', ascending=False).head(10)",
    "expected_output": "List of sellers with highest defect rate",
    "output_type": "Value",
    "category": "Top-N Risk by Metric",
    "python_code": "df.sort_values(by='order_defect_rate', ascending=False).head(10)"
  },
  {
    "prompt": "What\u2019s the average return rate by fulfillment service category?",
    "intent_description": "Risk + Category Join",
    "expected_code": "df.groupby('service_category')['return_rate'].mean().sort_values(ascending=False)",
    "expected_output": "Average return rate by service category",
    "output_type": "DataFrame",
    "category": "Risk + Category Join",
    "python_code": "df.groupby('service_category')['return_rate'].mean().sort_values(ascending=False)"
  },
  {
    "prompt": "List sellers with both high cancellation and late shipment rates.",
    "intent_description": "Multi-Metric Thresholds",
    "expected_code": "df[(df['cancellation_rate'] > 0.1) & (df['late_shipment_rate'] > 0.1)][['seller_name','cancellation_rate','late_shipment_rate']]",
    "expected_output": "Sellers failing in both cancellation and shipping",
    "output_type": "DataFrame",
    "category": "Multi-Metric Thresholds",
    "python_code": "df[(df['cancellation_rate'] > 0.1) & (df['late_shipment_rate'] > 0.1)][['seller_name','cancellation_rate','late_shipment_rate']]"
  },
  {
    "prompt": "Give me the average rating trend and 1-star reviews for fulfillment services.",
    "intent_description": "Customer Feedback Trends",
    "expected_code": "df[df['service_category'].str.contains('fulfillment', case=False)].groupby('service_category')[['rating_trend_score','one_star_review_pct']].mean()",
    "expected_output": "Rating trends and one-star % by fulfillment service",
    "output_type": "DataFrame",
    "category": "Customer Feedback Trends",
    "python_code": "df[df['service_category'].str.contains('fulfillment', case=False)].groupby('service_category')[['rating_trend_score','one_star_review_pct']].mean()"
  },
  {
    "prompt": "Find all sellers flagged for using suspicious IP addresses.",
    "intent_description": "IP-Based Risk Flags",
    "expected_code": "df[df['suspicious_ip_flag'] == 1][['seller_id', 'seller_name']]",
    "expected_output": "List of sellers using suspicious IPs",
    "output_type": "DataFrame",
    "category": "IP-Based Risk Flags",
    "python_code": "df[df['suspicious_ip_flag'] == 1][['seller_id', 'seller_name']]"
  },
  {
    "prompt": "Export defect rate and price volatility score for analysis.",
    "intent_description": "Correlation Prep",
    "expected_code": "df[['price_volatility_score','order_defect_rate']].dropna()",
    "expected_output": "Dataframe with defect rate and price volatility",
    "output_type": "DataFrame",
    "category": "Correlation Prep",
    "python_code": "df[['price_volatility_score','order_defect_rate']].dropna()"
  },
  {
    "prompt": "Identify new sellers (under 6 months) with high order defect rates.",
    "intent_description": "Risky Newcomers",
    "expected_code": "df[(df['account_age_months'] < 6) & (df['order_defect_rate'] > 0.1)][['seller_name','account_age_months','order_defect_rate']]",
    "expected_output": "New sellers with high order defect rate",
    "output_type": "DataFrame",
    "category": "Risky Newcomers",
    "python_code": "df[(df['account_age_months'] < 6) & (df['order_defect_rate'] > 0.1)][['seller_name','account_age_months','order_defect_rate']]"
  },
  {
    "prompt": "Find sellers with poor inventory turnover and high linked account risk.",
    "intent_description": "Inventory vs Fraud",
    "expected_code": "df[(df['inventory_turnover_score'] < 0.3) & (df['linked_account_score'] > 0.8)]",
    "expected_output": "Sellers with low inventory and high linked account risk",
    "output_type": "DataFrame",
    "category": "Inventory vs Fraud",
    "python_code": "df[(df['inventory_turnover_score'] < 0.3) & (df['linked_account_score'] > 0.8)]"
  },
  {
    "prompt": "Join all seller, engagement, and risk datasets into one table.",
    "intent_description": "Dataset Join",
    "expected_code": "pd.merge(seller_profiles, seller_engagements, on='seller_id', how='left').merge(seller_risk_metrics, on='engagement_id', how='left')",
    "expected_output": "Merged seller + engagement + risk dataset",
    "output_type": "Value",
    "category": "Dataset Join",
    "python_code": "pd.merge(seller_profiles, seller_engagements, on='seller_id', how='left').merge(seller_risk_metrics, on='engagement_id', how='left')"
  },
  {
    "prompt": "Recalculate the risk tier for sellers with high average defect rates.",
    "intent_description": "Tier Reclassification",
    "expected_code": "seller_profiles['risk_tier'] = seller_profiles.apply(lambda row: 'High' if row['seller_id'] in high_defect_sellers else row['risk_tier'], axis=1)",
    "expected_output": "Updated risk tier where average defect rate > 0.15",
    "output_type": "Value",
    "category": "Tier Reclassification",
    "python_code": "seller_profiles['risk_tier'] = seller_profiles.apply(lambda row: 'High' if row['seller_id'] in high_defect_sellers else row['risk_tier'], axis=1)"
  },
  {
    "prompt": "Create a complaint score using complaints + 2x policy violations.",
    "intent_description": "Derived Feature",
    "expected_code": "df.groupby('seller_id').apply(lambda x: (x['customer_complaint_volume'] + 2*x['policy_violation_count']).sum())",
    "expected_output": "Sum of complaints and 2\u00d7 violations grouped by seller",
    "output_type": "DataFrame",
    "category": "Derived Feature",
    "python_code": "df.groupby('seller_id').apply(lambda x: (x['customer_complaint_volume'] + 2*x['policy_violation_count']).sum())"
  },
  {
    "prompt": "Add a flag for sellers with high risk, >2 violations, and high defect rate.",
    "intent_description": "Multi-Dimensional Flag",
    "expected_code": "df.assign(at_risk_flag=lambda x: ((x['risk_tier'] == 'High') & (x['policy_violations_past_12m'] > 2) & (x['order_defect_rate'] > 0.1)).map({True:'Yes', False:'No'}))",
    "expected_output": "Flag column for sellers matching high risk, violation, and defect criteria",
    "output_type": "Value",
    "category": "Multi-Dimensional Flag",
    "python_code": "df.assign(at_risk_flag=lambda x: ((x['risk_tier'] == 'High') & (x['policy_violations_past_12m'] > 2) & (x['order_defect_rate'] > 0.1)).map({True:'Yes', False:'No'}))"
  },
  {
    "prompt": "Standardize each seller\u2019s price volatility score.",
    "intent_description": "Normalized Feature",
    "expected_code": "df = df.sort_values(by='date'); df['rating_change'] = df['rating'].pct_change()",
    "expected_output": "Z-score normalized price volatility per seller",
    "output_type": "DataFrame",
    "category": "Normalized Feature",
    "python_code": "df = df.sort_values(by='date'); df['rating_change'] = df['rating'].pct_change()"
  },
  {
    "prompt": "Show engagement count per seller divided by their account age in months.",
    "intent_description": "Engagement Intensity",
    "expected_code": "df.groupby('seller_id').apply(lambda x: len(x)/max(x['account_age_months']))",
    "expected_output": "Average delivery time by business model",
    "output_type": "DataFrame",
    "category": "Engagement Intensity",
    "python_code": "df.groupby('seller_id').apply(lambda x: len(x)/max(x['account_age_months']))"
  },
  {
    "prompt": "Split full names into first and last name columns.",
    "intent_description": "String Splitting",
    "expected_code": "df[['full_name']].assign(first_name=lambda x: x['full_name'].str.split().str[0], last_name=lambda x: x['full_name'].str.split().str[-1])",
    "expected_output": "Seller engagement count divided by account age",
    "output_type": "DataFrame",
    "category": "String Splitting",
    "python_code": "df[['full_name']].assign(first_name=lambda x: x['full_name'].str.split().str[0], last_name=lambda x: x['full_name'].str.split().str[-1])"
  },
  {
    "prompt": "Replace all 'N/A' entries in the address column with NULLs.",
    "intent_description": "Column Replacement",
    "expected_code": "df['address'] = df['address'].replace('N/A', pd.NA)",
    "expected_output": "Dataframe with separate first/last names from full name",
    "output_type": "DataFrame",
    "category": "Column Replacement",
    "python_code": "df['address'] = df['address'].replace('N/A', pd.NA)"
  },
  {
    "prompt": "Create a new column showing profit as revenue minus cost.",
    "intent_description": "Derived Column from Math",
    "expected_code": "df['profit'] = df['revenue'] - df['cost']",
    "expected_output": "'N/A' in address replaced with null",
    "output_type": "DataFrame",
    "category": "Derived Column from Math",
    "python_code": "df['profit'] = df['revenue'] - df['cost']"
  },
  {
    "prompt": "Add a flag for sellers who had more than 3 policy violations and high defect rate.",
    "intent_description": "Boolean Flag from Rule",
    "expected_code": "df['flag'] = ((df['policy_violation_count'] > 3) & (df['order_defect_rate'] > 0.1))",
    "expected_output": "New profit column from revenue minus cost",
    "output_type": "DataFrame",
    "category": "Boolean Flag from Rule",
    "python_code": "df['flag'] = ((df['policy_violation_count'] > 3) & (df['order_defect_rate'] > 0.1))"
  },
  {
    "prompt": "Get the top 3 sellers by order value for each region.",
    "intent_description": "Top-N by Group",
    "expected_code": "df.groupby('region').apply(lambda x: x.sort_values(by='order_value', ascending=False).head(3)).reset_index(drop=True)",
    "expected_output": "Flag for policy violations >3 & defect rate > 0.1",
    "output_type": "DataFrame",
    "category": "Top-N by Group",
    "python_code": "df.groupby('region').apply(lambda x: x.sort_values(by='order_value', ascending=False).head(3)).reset_index(drop=True)"
  },
  {
    "prompt": "Show the 7-day rolling average of order value.",
    "intent_description": "Rolling Metrics",
    "expected_code": "df = df.sort_values(by='date'); df['rolling_avg'] = df['order_value'].rolling(7).mean()",
    "expected_output": "Top 3 sellers per region by order value",
    "output_type": "DataFrame",
    "category": "Rolling Metrics",
    "python_code": "df = df.sort_values(by='date'); df['rolling_avg'] = df['order_value'].rolling(7).mean()"
  },
  {
    "prompt": "Find all sellers whose descriptions mention the word 'organic'.",
    "intent_description": "Text Contains Filter",
    "expected_code": "df[df['description'].str.contains('organic', case=False, na=False)]",
    "expected_output": "7-day rolling average of order values",
    "output_type": "DataFrame",
    "category": "Text Contains Filter",
    "python_code": "df[df['description'].str.contains('organic', case=False, na=False)]"
  },
  {
    "prompt": "Combine the city and state into a single 'location' field.",
    "intent_description": "Column Concatenation",
    "expected_code": "df['location'] = df['city'] + ', ' + df['state']",
    "expected_output": "Sellers whose description includes 'organic'",
    "output_type": "DataFrame",
    "category": "Column Concatenation",
    "python_code": "df['location'] = df['city'] + ', ' + df['state']"
  },
  {
    "prompt": "Convert each service category into numeric codes for modeling.",
    "intent_description": "Category Encoding",
    "expected_code": "df['cat_code'] = df['service_category'].astype('category').cat.codes",
    "expected_output": "Combined city and state into a new column",
    "output_type": "DataFrame",
    "category": "Category Encoding",
    "python_code": "df['cat_code'] = df['service_category'].astype('category').cat.codes"
  },
  {
    "prompt": "Convert the order date from string to datetime format.",
    "intent_description": "Data Type Conversion",
    "expected_code": "df['date_column'] = pd.to_datetime(df['date_column'])",
    "expected_output": "Service category converted to integer codes",
    "output_type": "DataFrame",
    "category": "Data Type Conversion",
    "python_code": "df['date_column'] = pd.to_datetime(df['date_column'])"
  },
  {
    "prompt": "Remove duplicate seller records using their seller ID.",
    "intent_description": "Deduplication",
    "expected_code": "df.drop_duplicates(subset='seller_id')",
    "expected_output": "Date column converted from string to datetime",
    "output_type": "Value",
    "category": "Deduplication",
    "python_code": "df.drop_duplicates(subset='seller_id')"
  },
  {
    "prompt": "Calculate the month-over-month percent change in ratings.",
    "intent_description": "Percent Change",
    "expected_code": "df = df.sort_values(by='date'); df['pct_change'] = df['rating'].pct_change()",
    "expected_output": "Duplicates removed by seller_id",
    "output_type": "DataFrame",
    "category": "Percent Change",
    "python_code": "df = df.sort_values(by='date'); df['pct_change'] = df['rating'].pct_change()"
  }
]