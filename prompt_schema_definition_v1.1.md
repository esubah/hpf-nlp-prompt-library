# üìê Prompt Library Schema Definition

This document defines the keys and structure of each prompt used in the HPFN NLP Prompt Library.

---

## üîë Fields

| Field               | Type    | Required | Description                                                                 |
|--------------------|---------|----------|-----------------------------------------------------------------------------|
| `prompt`           | string  | ‚úÖ Yes   | The natural language query or instruction.                                |
| `intent_description` | string | ‚úÖ Yes   | Short description of the action being asked (e.g., filter, group, join).  |
| `expected_code` / `python_code` | string | ‚úÖ Yes   | Pandas code expected to be generated by the model/tool.                   |
| `expected_output`  | string  | ‚úÖ Yes   | Textual description of the expected result/output.                        |
| `output_type`      | string  | ‚úÖ Yes   | One of: `DataFrame`, `Value`, `Plot`. Used to determine how output is shown. |
| `complexity_level` | string  | ‚úÖ Yes   | One of: `Simple`, `Intermediate`, or `Nested`. Categorizes prompt difficulty. |
| `category`         | string  | ‚úÖ Yes   | Functional use case category (e.g., GroupBy, Join, Derived Column).       |
| `model_generated_code` | string | No    | Output generated by the LLM during testing (recorded after execution).    |
| `test_status`      | string  | No       | Outcome from prompt testing: `Pass`, `Fail`, or `Inconclusive`.           |
| `error_notes`      | string  | No       | Optional log of errors, issues, or mismatches for the prompt.             |

---

## üß™ Sample Entry (JSON)

```json
{
  "prompt": "Show average discount by fulfillment model.",
  "intent_description": "GroupBy Aggregation",
  "expected_code": "df.groupby('fulfillment_model')['discount'].mean()",
  "expected_output": "Average discount per group",
  "output_type": "DataFrame",
  "complexity_level": "Simple",
  "category": "GroupBy"
}
```

---

## üìö Usage Context

This schema supports:
- Prompt evaluation logs
- LLM training and testing pipelines
- UI filtering and routing logic
- Prompt chaining and complexity analysis