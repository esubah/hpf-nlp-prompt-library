prompt,intent_description,expected_code,expected_output,output_type,category,python_code,complexity_level
Show me the top 5 sellers with the highest internal risk rating and most escalations.,Ranking with CASE + Sorting,"df.sort_values(by=['internal_risk_rating', 'escalation_count'], ascending=[False, False]).head(5)",Top 5 sellers sorted by risk rating and escalation count,Value,Sort / Ranking,"df.sort_values(by=['internal_risk_rating', 'escalation_count'], ascending=[False, False]).head(5)",Nested
"What’s the average identity, UBO, and geo risk score by service category?",Aggregated Averages by Group,"df.groupby('service_category')[['identity_verification_score', 'ubo_transparency_score', 'geo_risk_score']].mean().sort_values('geo_risk_score', ascending=False)","Average identity, UBO, and geo scores per service category",DataFrame,GroupBy,"df.groupby('service_category')[['identity_verification_score', 'ubo_transparency_score', 'geo_risk_score']].mean().sort_values('geo_risk_score', ascending=False)",Nested
List sellers who had very high onboarding time anomalies.,Anomaly Detection,"df[df['onboarding_time_anomaly'] > 0.8].sort_values('onboarding_time_anomaly', ascending=False)",Sellers with high anomaly scores in onboarding,DataFrame,Datetime Logic,"df[df['onboarding_time_anomaly'] > 0.8].sort_values('onboarding_time_anomaly', ascending=False)",Intermediate
"Group sellers by account age (New, Mid, Established) and show percent with high risk.",Bucketizing with CASE,"df.assign(age_group=pd.cut(df['registration_age_months'], bins=[0,12,36,999], labels=['New','Mid','Established'])).groupby('age_group').agg({'seller_id':'count', 'internal_risk_rating': lambda x: (x=='High').mean()*100})",Seller count and high-risk % by account age group,DataFrame,General,"df.assign(age_group=pd.cut(df['registration_age_months'], bins=[0,12,36,999], labels=['New','Mid','Established'])).groupby('age_group').agg({'seller_id':'count', 'internal_risk_rating': lambda x: (x=='High').mean()*100})",Nested
How many sellers haven't completed bank verification?,Missing Value Filter,df[df['bank_account_verification'] == 0].shape[0],Total number of sellers missing bank verification,DataFrame,General,df[df['bank_account_verification'] == 0].shape[0],Intermediate
What’s the correlation between document completeness and remediation effectiveness?,Correlation Analysis,df['doc_completeness_score'].corr(df['remediation_effectiveness_score']),Correlation value between document completeness and remediation scores,DataFrame,General,df['doc_completeness_score'].corr(df['remediation_effectiveness_score']),Nested
Which sellers had different internal risk ratings over time?,Behavioral Volatility,df.groupby('seller_id')['internal_risk_rating'].nunique().reset_index().query('internal_risk_rating > 1'),Sellers with multiple distinct risk ratings,DataFrame,Datetime Logic,df.groupby('seller_id')['internal_risk_rating'].nunique().reset_index().query('internal_risk_rating > 1'),Intermediate
Find high-risk sellers with control coverage scores below 70.,Multi-Criteria Filter,df[(df['internal_risk_rating']=='High') & (df['control_coverage_score'] < 70)].sort_values('control_coverage_score'),List of high-risk sellers with low control coverage score,DataFrame,General,df[(df['internal_risk_rating']=='High') & (df['control_coverage_score'] < 70)].sort_values('control_coverage_score'),Intermediate
Give me a count of sellers by service category and their risk level.,Heatmap Layout,"df.groupby(['service_category', 'internal_risk_rating'])['seller_id'].count().reset_index()",Seller count per risk level and service category,DataFrame,General,"df.groupby(['service_category', 'internal_risk_rating'])['seller_id'].count().reset_index()",Nested
Which service categories have the most historical compliance issues?,Policy Violation Totals,df.groupby('service_category')['historical_compliance_findings'].sum().sort_values(ascending=False).head(5),Top 5 service categories with the most compliance issues,DataFrame,General,df.groupby('service_category')['historical_compliance_findings'].sum().sort_values(ascending=False).head(5),Intermediate
Show the 10 sellers with the worst order defect rates.,Top-N Risk by Metric,"df.sort_values(by='order_defect_rate', ascending=False).head(10)",List of sellers with highest defect rate,Value,General,"df.sort_values(by='order_defect_rate', ascending=False).head(10)",Intermediate
What’s the average return rate by fulfillment service category?,Risk + Category Join,df.groupby('service_category')['return_rate'].mean().sort_values(ascending=False),Average return rate by service category,DataFrame,GroupBy,df.groupby('service_category')['return_rate'].mean().sort_values(ascending=False),Simple
List sellers with both high cancellation and late shipment rates.,Multi-Metric Thresholds,"df[(df['cancellation_rate'] > 0.1) & (df['late_shipment_rate'] > 0.1)][['seller_name','cancellation_rate','late_shipment_rate']]",Sellers failing in both cancellation and shipping,DataFrame,General,"df[(df['cancellation_rate'] > 0.1) & (df['late_shipment_rate'] > 0.1)][['seller_name','cancellation_rate','late_shipment_rate']]",Nested
Give me the average rating trend and 1-star reviews for fulfillment services.,Customer Feedback Trends,"df[df['service_category'].str.contains('fulfillment', case=False)].groupby('service_category')[['rating_trend_score','one_star_review_pct']].mean()",Rating trends and one-star % by fulfillment service,DataFrame,GroupBy,"df[df['service_category'].str.contains('fulfillment', case=False)].groupby('service_category')[['rating_trend_score','one_star_review_pct']].mean()",Nested
Find all sellers flagged for using suspicious IP addresses.,IP-Based Risk Flags,"df[df['suspicious_ip_flag'] == 1][['seller_id', 'seller_name']]",List of sellers using suspicious IPs,DataFrame,General,"df[df['suspicious_ip_flag'] == 1][['seller_id', 'seller_name']]",Intermediate
Export defect rate and price volatility score for analysis.,Correlation Prep,"df[['price_volatility_score','order_defect_rate']].dropna()",Dataframe with defect rate and price volatility,DataFrame,General,"df[['price_volatility_score','order_defect_rate']].dropna()",Nested
Identify new sellers (under 6 months) with high order defect rates.,Risky Newcomers,"df[(df['account_age_months'] < 6) & (df['order_defect_rate'] > 0.1)][['seller_name','account_age_months','order_defect_rate']]",New sellers with high order defect rate,DataFrame,Datetime Logic,"df[(df['account_age_months'] < 6) & (df['order_defect_rate'] > 0.1)][['seller_name','account_age_months','order_defect_rate']]",Intermediate
Find sellers with poor inventory turnover and high linked account risk.,Inventory vs Fraud,df[(df['inventory_turnover_score'] < 0.3) & (df['linked_account_score'] > 0.8)],Sellers with low inventory and high linked account risk,DataFrame,General,df[(df['inventory_turnover_score'] < 0.3) & (df['linked_account_score'] > 0.8)],Nested
"Join all seller, engagement, and risk datasets into one table.",Dataset Join,"pd.merge(seller_profiles, seller_engagements, on='seller_id', how='left').merge(seller_risk_metrics, on='engagement_id', how='left')",Merged seller + engagement + risk dataset,Value,Join,"pd.merge(seller_profiles, seller_engagements, on='seller_id', how='left').merge(seller_risk_metrics, on='engagement_id', how='left')",Nested
Recalculate the risk tier for sellers with high average defect rates.,Tier Reclassification,"seller_profiles['risk_tier'] = seller_profiles.apply(lambda row: 'High' if row['seller_id'] in high_defect_sellers else row['risk_tier'], axis=1)",Updated risk tier where average defect rate > 0.15,Value,GroupBy,"seller_profiles['risk_tier'] = seller_profiles.apply(lambda row: 'High' if row['seller_id'] in high_defect_sellers else row['risk_tier'], axis=1)",Intermediate
Create a complaint score using complaints + 2x policy violations.,Derived Feature,df.groupby('seller_id').apply(lambda x: (x['customer_complaint_volume'] + 2*x['policy_violation_count']).sum()),Sum of complaints and 2× violations grouped by seller,DataFrame,Derived Column,df.groupby('seller_id').apply(lambda x: (x['customer_complaint_volume'] + 2*x['policy_violation_count']).sum()),Intermediate
"Add a flag for sellers with high risk, >2 violations, and high defect rate.",Multi-Dimensional Flag,"df.assign(at_risk_flag=lambda x: ((x['risk_tier'] == 'High') & (x['policy_violations_past_12m'] > 2) & (x['order_defect_rate'] > 0.1)).map({True:'Yes', False:'No'}))","Flag column for sellers matching high risk, violation, and defect criteria",Value,General,"df.assign(at_risk_flag=lambda x: ((x['risk_tier'] == 'High') & (x['policy_violations_past_12m'] > 2) & (x['order_defect_rate'] > 0.1)).map({True:'Yes', False:'No'}))",Nested
Standardize each seller’s price volatility score.,Normalized Feature,df = df.sort_values(by='date'); df['rating_change'] = df['rating'].pct_change(),Z-score normalized price volatility per seller,DataFrame,General,df = df.sort_values(by='date'); df['rating_change'] = df['rating'].pct_change(),Intermediate
Show engagement count per seller divided by their account age in months.,Engagement Intensity,df.groupby('seller_id').apply(lambda x: len(x)/max(x['account_age_months'])),Average delivery time by business model,DataFrame,Datetime Logic,df.groupby('seller_id').apply(lambda x: len(x)/max(x['account_age_months'])),Intermediate
Split full names into first and last name columns.,String Splitting,"df[['full_name']].assign(first_name=lambda x: x['full_name'].str.split().str[0], last_name=lambda x: x['full_name'].str.split().str[-1])",Seller engagement count divided by account age,DataFrame,Split,"df[['full_name']].assign(first_name=lambda x: x['full_name'].str.split().str[0], last_name=lambda x: x['full_name'].str.split().str[-1])",Nested
Replace all 'N/A' entries in the address column with NULLs.,Column Replacement,"df['address'] = df['address'].replace('N/A', pd.NA)",Dataframe with separate first/last names from full name,DataFrame,General,"df['address'] = df['address'].replace('N/A', pd.NA)",Intermediate
Create a new column showing profit as revenue minus cost.,Derived Column from Math,df['profit'] = df['revenue'] - df['cost'],'N/A' in address replaced with null,DataFrame,Derived Column,df['profit'] = df['revenue'] - df['cost'],Intermediate
Add a flag for sellers who had more than 3 policy violations and high defect rate.,Boolean Flag from Rule,df['flag'] = ((df['policy_violation_count'] > 3) & (df['order_defect_rate'] > 0.1)),New profit column from revenue minus cost,DataFrame,General,df['flag'] = ((df['policy_violation_count'] > 3) & (df['order_defect_rate'] > 0.1)),Nested
Get the top 3 sellers by order value for each region.,Top-N by Group,"df.groupby('region').apply(lambda x: x.sort_values(by='order_value', ascending=False).head(3)).reset_index(drop=True)",Flag for policy violations >3 & defect rate > 0.1,DataFrame,Sort / Ranking,"df.groupby('region').apply(lambda x: x.sort_values(by='order_value', ascending=False).head(3)).reset_index(drop=True)",Simple
Show the 7-day rolling average of order value.,Rolling Metrics,df = df.sort_values(by='date'); df['rolling_avg'] = df['order_value'].rolling(7).mean(),Top 3 sellers per region by order value,DataFrame,GroupBy,df = df.sort_values(by='date'); df['rolling_avg'] = df['order_value'].rolling(7).mean(),Simple
Find all sellers whose descriptions mention the word 'organic'.,Text Contains Filter,"df[df['description'].str.contains('organic', case=False, na=False)]",7-day rolling average of order values,DataFrame,General,"df[df['description'].str.contains('organic', case=False, na=False)]",Intermediate
Combine the city and state into a single 'location' field.,Column Concatenation,"df['location'] = df['city'] + ', ' + df['state']",Sellers whose description includes 'organic',DataFrame,General,"df['location'] = df['city'] + ', ' + df['state']",Nested
Convert each service category into numeric codes for modeling.,Category Encoding,df['cat_code'] = df['service_category'].astype('category').cat.codes,Combined city and state into a new column,DataFrame,General,df['cat_code'] = df['service_category'].astype('category').cat.codes,Intermediate
Convert the order date from string to datetime format.,Data Type Conversion,df['date_column'] = pd.to_datetime(df['date_column']),Service category converted to integer codes,DataFrame,Datetime Logic,df['date_column'] = pd.to_datetime(df['date_column']),Intermediate
Remove duplicate seller records using their seller ID.,Deduplication,df.drop_duplicates(subset='seller_id'),Date column converted from string to datetime,Value,General,df.drop_duplicates(subset='seller_id'),Intermediate
Calculate the month-over-month percent change in ratings.,Percent Change,df = df.sort_values(by='date'); df['pct_change'] = df['rating'].pct_change(),Duplicates removed by seller_id,DataFrame,Datetime Logic,df = df.sort_values(by='date'); df['pct_change'] = df['rating'].pct_change(),Intermediate
